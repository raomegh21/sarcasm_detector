{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41abb2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Initialize empty lists to store data\n",
    "sentences = []\n",
    "labels = []\n",
    "urls = []\n",
    "\n",
    "# Open the JSON file\n",
    "with open('Sarcasm_Headlines_Dataset.json', 'r') as f:\n",
    "    # Read each line (assuming each line is a separate JSON object)\n",
    "    for line in f:\n",
    "        # Parse the JSON object in the line\n",
    "        item = json.loads(line)\n",
    "        sentences.append(item['headline'])\n",
    "        labels.append(item['is_sarcastic'])\n",
    "        urls.append(item['article_link'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57ecf51e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  308 15115   679  3337  2298    48   382  2576 15116     6  2577  8434\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0     0     0     0     0     0     0     0     0\n",
      "     0     0     0     0]\n",
      "(26709, 40)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "tokenizer=Tokenizer(oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(sentences)\n",
    "word_index=tokenizer.word_index\n",
    "#print(word_index)\n",
    "\n",
    "sequences=tokenizer.texts_to_sequences(sentences)\n",
    "paddin=pad_sequences(sequences,padding='post')\n",
    "print(paddin[0])\n",
    "print(paddin.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d1a1848e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "training_size=26709\n",
    "vocab_size=10000\n",
    "embedding_dim=100\n",
    "#split into training and testing\n",
    "training_sentences=sentences[0:training_size]\n",
    "testing_sentences=sentences[training_size:]\n",
    "training_labels=labels[0:training_size]\n",
    "testing_labels=labels[training_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "25b490d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer=Tokenizer(num_words=vocab_size,oov_token='<OOV>')\n",
    "tokenizer.fit_on_texts(training_sentences)\n",
    "word_index=tokenizer.word_index\n",
    "#creating sequence and padding for test and train data\n",
    "training_sequences=tokenizer.texts_to_sequences(training_sentences)\n",
    "training_padded=pad_sequences(training_sequences,maxlen=100,padding='post',truncating='post')\n",
    "testing_sequences=tokenizer.texts_to_sequences(testing_sentences)\n",
    "testing_padded=pad_sequences(testing_sequences,maxlen=100,padding='post',truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c3cd68c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into numpy arrays\n",
    "import numpy as np\n",
    "training_padded = np.array(training_padded)\n",
    "training_labels = np.array(training_labels)\n",
    "testing_padded = np.array(testing_padded)\n",
    "testing_labels = np.array(testing_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c2083bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "835/835 - 16s - loss: 0.5313 - accuracy: 0.7180 - 16s/epoch - 20ms/step\n",
      "Epoch 2/30\n",
      "835/835 - 14s - loss: 0.3025 - accuracy: 0.8755 - 14s/epoch - 17ms/step\n",
      "Epoch 3/30\n",
      "835/835 - 14s - loss: 0.2408 - accuracy: 0.9039 - 14s/epoch - 16ms/step\n",
      "Epoch 4/30\n",
      "835/835 - 14s - loss: 0.2057 - accuracy: 0.9191 - 14s/epoch - 16ms/step\n",
      "Epoch 5/30\n",
      "835/835 - 14s - loss: 0.1825 - accuracy: 0.9287 - 14s/epoch - 16ms/step\n",
      "Epoch 6/30\n",
      "835/835 - 15s - loss: 0.1615 - accuracy: 0.9392 - 15s/epoch - 17ms/step\n",
      "Epoch 7/30\n",
      "835/835 - 15s - loss: 0.1496 - accuracy: 0.9431 - 15s/epoch - 17ms/step\n",
      "Epoch 8/30\n",
      "835/835 - 14s - loss: 0.1353 - accuracy: 0.9490 - 14s/epoch - 17ms/step\n",
      "Epoch 9/30\n",
      "835/835 - 14s - loss: 0.1275 - accuracy: 0.9526 - 14s/epoch - 17ms/step\n",
      "Epoch 10/30\n",
      "835/835 - 14s - loss: 0.1180 - accuracy: 0.9565 - 14s/epoch - 17ms/step\n",
      "Epoch 11/30\n",
      "835/835 - 14s - loss: 0.1070 - accuracy: 0.9624 - 14s/epoch - 17ms/step\n",
      "Epoch 12/30\n",
      "835/835 - 15s - loss: 0.1041 - accuracy: 0.9614 - 15s/epoch - 17ms/step\n",
      "Epoch 13/30\n",
      "835/835 - 14s - loss: 0.0993 - accuracy: 0.9635 - 14s/epoch - 17ms/step\n",
      "Epoch 14/30\n",
      "835/835 - 14s - loss: 0.0943 - accuracy: 0.9653 - 14s/epoch - 16ms/step\n",
      "Epoch 15/30\n",
      "835/835 - 14s - loss: 0.0860 - accuracy: 0.9699 - 14s/epoch - 17ms/step\n",
      "Epoch 16/30\n",
      "835/835 - 14s - loss: 0.0825 - accuracy: 0.9708 - 14s/epoch - 16ms/step\n",
      "Epoch 17/30\n",
      "835/835 - 14s - loss: 0.0788 - accuracy: 0.9720 - 14s/epoch - 16ms/step\n",
      "Epoch 18/30\n",
      "835/835 - 14s - loss: 0.0748 - accuracy: 0.9735 - 14s/epoch - 16ms/step\n",
      "Epoch 19/30\n",
      "835/835 - 14s - loss: 0.0704 - accuracy: 0.9757 - 14s/epoch - 16ms/step\n",
      "Epoch 20/30\n",
      "835/835 - 14s - loss: 0.0697 - accuracy: 0.9754 - 14s/epoch - 17ms/step\n",
      "Epoch 21/30\n",
      "835/835 - 14s - loss: 0.0662 - accuracy: 0.9762 - 14s/epoch - 16ms/step\n",
      "Epoch 22/30\n",
      "835/835 - 14s - loss: 0.0621 - accuracy: 0.9775 - 14s/epoch - 16ms/step\n",
      "Epoch 23/30\n",
      "835/835 - 14s - loss: 0.0610 - accuracy: 0.9785 - 14s/epoch - 16ms/step\n",
      "Epoch 24/30\n",
      "835/835 - 14s - loss: 0.0587 - accuracy: 0.9800 - 14s/epoch - 17ms/step\n",
      "Epoch 25/30\n",
      "835/835 - 14s - loss: 0.0548 - accuracy: 0.9815 - 14s/epoch - 16ms/step\n",
      "Epoch 26/30\n",
      "835/835 - 14s - loss: 0.0566 - accuracy: 0.9800 - 14s/epoch - 16ms/step\n",
      "Epoch 27/30\n",
      "835/835 - 14s - loss: 0.0523 - accuracy: 0.9814 - 14s/epoch - 16ms/step\n",
      "Epoch 28/30\n",
      "835/835 - 14s - loss: 0.0509 - accuracy: 0.9823 - 14s/epoch - 17ms/step\n",
      "Epoch 29/30\n",
      "835/835 - 14s - loss: 0.0474 - accuracy: 0.9842 - 14s/epoch - 16ms/step\n",
      "Epoch 30/30\n",
      "835/835 - 14s - loss: 0.0465 - accuracy: 0.9841 - 14s/epoch - 16ms/step\n"
     ]
    }
   ],
   "source": [
    "#model\n",
    "model=tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size,embedding_dim,input_length=100),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(24,activation='relu'),\n",
    "    tf.keras.layers.Dense(1,activation='sigmoid')\n",
    "    \n",
    "])\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "history=model.fit(training_padded,training_labels,epochs=30,validation_data=(testing_padded,testing_labels),verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "841cbafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 254ms/step\n",
      "[[0.9999401 ]\n",
      " [0.10061174]]\n"
     ]
    }
   ],
   "source": [
    "#testing\n",
    "sentence=['It’s okay if you don’t like me. Not everyone has good taste.',\n",
    "           'Tomorrow is Friday']\n",
    "sequences=tokenizer.texts_to_sequences(sentence)\n",
    "padded=pad_sequences(sequences,maxlen=100,padding='post',truncating='post')\n",
    "print(model.predict(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6dbaee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#since 0.99 is near to 1 -sarcastic\n",
    "#0.10 is near to 0 -not sarcastic"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
